{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Config\n",
    "sns.set(color_codes=True)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from useful_functions import read_in_election_results, calc_marginal_within\n",
    "from useful_functions import score_campaigns_difference, score_campaigns_uns,score_campaigns_mrp\n",
    "from useful_functions import read_in_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score constituencies\n",
    "\n",
    "Read in election results and calculate various scoring metrics for the labour campaing in each constituency\n",
    "\n",
    "- `base` : Simply the % share of votes Labour recieved in a constituency\n",
    "- `diff` : Difference in number of votes between an election year and the comparisson year\n",
    "- `uns` : Swing to/from labour in a constituency minus the national average swing\n",
    "- `mrp` : Compare the Labour vote share with the YOUGOV MRP poll carried out 4 weeks before an election, only available for GE17 and GE19\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/010.csv' does not exist: b'data/010.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-415e746db8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0melection_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_in_election_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/camgainlab/lab_campaigns/useful_functions.py\u001b[0m in \u001b[0;36mread_in_election_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_in_election_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mge10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadge10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/010.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mge15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadge15\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/ge2015.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mge17\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadge17\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/ge2017.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/camgainlab/lab_campaigns/useful_functions.py\u001b[0m in \u001b[0;36mreadge10\u001b[0;34m(datafile)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadge10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mge10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mge10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mge10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Constituency ID\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ons_id\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mge10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mge10\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mge10\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Region\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Northern Ireland\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/democracy/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/democracy/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/democracy/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/democracy/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/democracy/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/010.csv' does not exist: b'data/010.csv'"
     ]
    }
   ],
   "source": [
    "election_results = read_in_election_results() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick year of interest, and one to compare with (neccesary for some of the scoring methods)\n",
    "year = 19 # 2019 election\n",
    "compare_year = 17 # normally the previous election year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.DataFrame(election_results[year]['lab_pc'],\n",
    "                    index=election_results[year].index)\n",
    "\n",
    "diff = score_campaigns_difference(election_results[year], \n",
    "                                  election_results[compare_year])\n",
    "\n",
    "uns  = score_campaigns_uns(election_results[year], \n",
    "                           election_results[compare_year])\n",
    "\n",
    "mrp  = score_campaigns_mrp(election_results[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all scoring metrics into one database `scores`\n",
    "scores = pd.concat( [election_results[year]['Constituency'],\n",
    "                     base['lab_pc'], diff['difference'],uns['difference'],mrp['difference'] ],\n",
    "                    axis=1, verify_integrity=True, sort=True)\n",
    "scores.columns = ['Constituency','base','diff','uns','mrp']\n",
    "scores.sort_values('uns',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(scores['base'],scores['uns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(scores['uns'],scores['mrp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seats that labour won by, or were within a certain percentage of winning\n",
    "marginals = calc_marginal_within(0.10,election_results[compare_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select demographic data to compare constituencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = read_in_census()\n",
    "# only want rows we have election data for\n",
    "census = census.loc[election_results[year].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['c11PopulationDensity',\n",
    "            'c11HouseOwned',\n",
    "            'c11CarsNone',\n",
    "            'c11EthnicityWhite',\n",
    "            'c11Unemployed',\n",
    "            'c11Retired',\n",
    "            'c11FulltimeStudent',\n",
    "            'c11Age65to74',\n",
    "            'c11DeprivedNone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_data = census[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only want constituencies we have complete data for\n",
    "demographic_data = demographic_data.dropna()\n",
    "# Speaker seats have incomplete voting data\n",
    "speaker_seats = census.index[census['constituency_name'].isin(['Chorley', 'Buckingham'])]\n",
    "demographic_data = demographic_data.drop(speaker_seats)\n",
    "\n",
    "loss = set(census.index) - set(demographic_data.index)\n",
    "print('Loss =',len(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some lookup containers\n",
    "constits_id = demographic_data.index\n",
    "constits_name = list(census.loc[constits_id]['constituency_name'])\n",
    "id_to_name = {id_:name for id_,name in zip(constits_id, constits_name)}\n",
    "name_to_id = {name:id_ for id_,name in zip(constits_id, constits_name)}\n",
    "id_to_index = {onsid:i for i,onsid in enumerate(constits_id)}\n",
    "name_to_index = {name:i for i,name in enumerate(constits_name)}\n",
    "\n",
    "scores = scores.loc[constits_id] # only interested in these constits now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the spread of constituencies based on their demographics.\n",
    "\n",
    "The graph below shows contituencies close to similar constituencies. Do not read too much into the axes. Points are coloured by their labour swing relative to the national labour swing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#name_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "embedding = Isomap(n_components=2)\n",
    "\n",
    "X_transformed = embedding.fit_transform(demographic_data)\n",
    "x = pd.Series(X_transformed[:,0])\n",
    "y = pd.Series(X_transformed[:,1])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "hues = np.array(marginals.loc[constits_id])\n",
    "hues = np.array(scores['uns']-0.079) - 0.079\n",
    "#hues = list(scores['base'])\n",
    "hues = np.array(local_density['density'])\n",
    "ax = sns.scatterplot(x=x,y=y,hue=hues, palette='RdYlBu_r')\n",
    "\n",
    "for constit in ['Bethnal Green and Bow', 'Hackney South and Shoreditch','Christchurch',\n",
    "               'Bradford West','Bassetlaw','Wentworth and Dearne','Blyth Valley','Chingford and Woodford Green']:\n",
    "    ax.text(x[name_to_index[constit]], \n",
    "            y[name_to_index[constit]],\n",
    "                        constit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn import preprocessing\n",
    "#pca = PCA(n_components=2)\n",
    "#X_transformed = pca.fit_transform(demographic_data)\n",
    "#x_pca = pd.Series(X_transformed[:,0])\n",
    "#y_pca = pd.Series(X_transformed[:,1])\n",
    "\n",
    "#plt.figure(figsize=(6,6))\n",
    "#hues = np.array(scores['uns']-0.079)\n",
    "#hues *= 100\n",
    "#hues = np.array(hues,dtype=int)\n",
    "#hues = list(scores['base'])\n",
    "#ax = sns.scatterplot(x=x_pca,y=y_pca,hue=hues, palette='RdYlBu_r')\n",
    "\n",
    "#for constit in ['Chingford and Woodford Green']:\n",
    "#    ax.text(x_pca[name_to_index[constit]], \n",
    "#            y_pca[name_to_index[constit]],\n",
    "#                        constit)\n",
    "\n",
    "##pd.DataFrame({f:c for f,c in zip(features,pca.components_[0])})\n",
    "#for f,c in zip(features,pca.components_[0]):\n",
    "#    print(f,c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show distribution of distances between constituencies\n",
    "X_scaled = preprocessing.scale(demographic_data)\n",
    "dist_matrix = pairwise_distances(X_scaled)\n",
    "sns.distplot(np.ndarray.flatten(dist_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['Constituency'].iloc[np.where(dist_matrix == np.max(dist_matrix))[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate confidence that a local campaign was succesful\n",
    "\n",
    "All constituencies are compared with each other.\n",
    "\n",
    "We calculate the 'distance' between each constituency according their demographics. Similar constituencies, based on the features chosen above, will have a small distance between them.\n",
    "\n",
    "We then calculate the relative score between each campaign.\n",
    "\n",
    "This relative score is divided by the distance between each constituency. Our confidence in a constituencies campaing is the sum of this value between all other constituencies.\n",
    "\n",
    "If constituency A scored much better than constituency B, and they are very similar in demographics, A will recieve a positive contribution and B will recieve a negative one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(X, cutoff=None):\n",
    "    return pairwise_distances(X)\n",
    "\n",
    "def distance_cutoff(X, cutoff):\n",
    "    dist_matrix = distance(X)\n",
    "    mask = dist_matrix > cutoff\n",
    "    dist_matrix[mask] = 0\n",
    "    return dist_matrix\n",
    "\n",
    "def distance_rescale(X, exponent=math.e):\n",
    "    dist_matrix = distance(X)\n",
    "    return exponent**dist_matrix\n",
    "    \n",
    "def calc_significance_matrix(demographic_data, constit_score, \n",
    "                             dist_func=distance, **kwargs):\n",
    "    X_scaled      = preprocessing.scale(demographic_data)\n",
    "    dist_matrix   = dist_func(X_scaled, **kwargs)\n",
    "    constit_score = preprocessing.scale(constit_score)\n",
    "    score_matrix  = constit_score[:,np.newaxis] - constit_score\n",
    "    significance  = np.zeros(score_matrix.shape) # need to initialise all to zero\n",
    "    np.divide( score_matrix, dist_matrix, where=dist_matrix!=0,\n",
    "             out=significance)\n",
    "    return significance\n",
    "    \n",
    "def calc_campaign_conf(demographic_data, constit_score, \n",
    "                             dist_func=distance, **kwargs):\n",
    "    #assert np.all( demographic_data.index == constit_score.index )\n",
    "    significance = calc_significance_matrix(demographic_data, constit_score, dist_func, **kwargs)\n",
    "    return pd.Series(np.sum(significance,1),index=constits_id)\n",
    "\n",
    "def calc_local_density(demographic_data, dist_func=distance, **kwargs):\n",
    "    X_scaled      = preprocessing.scale(demographic_data)\n",
    "    dist_matrix   = dist_func(X_scaled, **kwargs)\n",
    "    local_density = np.zeros(dist_matrix.shape)\n",
    "    np.divide(np.ones(dist_matrix.shape), dist_matrix, where=dist_matrix!=0,\n",
    "             out=local_density)\n",
    "    return pd.Series(np.sum(local_density,1),index=constits_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 1\n",
    "results = pd.DataFrame({\n",
    "                        'constituency': constits_name,\n",
    "                        'uns': calc_campaign_conf(demographic_data, scores['uns']),\n",
    "                        'uns_cut': calc_campaign_conf(demographic_data, scores['uns'],distance_cutoff, cutoff=cutoff),\n",
    "                        'uns_rescale': calc_campaign_conf(demographic_data, scores['uns'],distance_rescale, exponent=10),\n",
    "                       }, index = constits_id)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_density = calc_local_density(demographic_data,dist_func=distance_rescale,exponent=10)\n",
    "local_density = pd.DataFrame({'constituency': constits_name,\n",
    "                   'density': local_density})\n",
    "results['density'] = local_density['density']\n",
    "results['uns_rescale_normal'] = results['uns_rescale'] / local_density['density']\n",
    "results.sort_values('uns_rescale_normal',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y=results['uns_rescale'],x=results['uns_rescale_normal'],\n",
    "                hue=results['density'])\n",
    "#sns.distplot(results['uns_rescale_normal'])\n",
    "#r2_score(results['uns_rescale'],results['uns_rescale_normal'])\n",
    "results['uns_rescale'].std() / results['uns_rescale_normal'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results[results['constituency']=='Chingford and Woodford Green']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows constituencies that according to this metric did well (red) or badly (blue). If a constituency is not similar to many others, the score is close to zero because we don't have much to compare to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "#sns.scatterplot(x=x,y=y,hue=np.tanh(np.array(results['uns_rescale'])/11.6), palette='RdYlBu_r')\n",
    "sns.scatterplot(x=x,y=y,hue=np.tanh(np.array(results['uns_rescale_normal'])), palette='RdYlBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=scores['uns'],y=results['uns_cut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=scores['uns'],y=results['uns_rescale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(results['uns_rescale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('uns_rescale',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_similar(constit, N=5):\n",
    "    index = id_to_index[constit]\n",
    "    dists = dist_matrix[index]\n",
    "    close_indexes = np.argsort(dists)\n",
    "    \n",
    "    df = pd.DataFrame({'name': id_to_name[constit],\n",
    "                       'distance': 0},\n",
    "                      index = [constit])\n",
    "\n",
    "    for i in range(1,N+1):\n",
    "        j = close_indexes[i]\n",
    "        df = df.append( pd.DataFrame({'name': constits_name[j],\n",
    "                                     'distance': dists[j]},\n",
    "                                     index = [constits_id[j]])\n",
    "                      )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_significances(constit, significance_matrix, scores, N=5):\n",
    "    index = id_to_index[constit]\n",
    "    dists = dist_matrix[index]\n",
    "    significances = significance_matrix[index]\n",
    "    most_signif = np.argsort(-abs(significances))\n",
    "\n",
    "    df = pd.DataFrame({'name': id_to_name[constit],\n",
    "                       'distance': 0,\n",
    "                       'election swing': scores.loc[constit],\n",
    "                       'score contribution': 0,\n",
    "                       },\n",
    "                      index = [constit])\n",
    "    \n",
    "    for i in range(N):\n",
    "        j = most_signif[i]\n",
    "        df = df.append( pd.DataFrame({'name': constits_name[j],\n",
    "                                      'distance': dists[j],\n",
    "                                      'election swing': scores[constits_id[j]] - 0.079,\n",
    "                                      'score contribution': significances[j]\n",
    "                                     },\n",
    "                                     index = [constits_id[j]])\n",
    "                      )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate a constituency's score\n",
    "\n",
    "Define a constituency of interest `coi` in the cell below to see where it's score comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coi needs to a be an ONSID\n",
    "coi = name_to_id['Vale Of Glamorgan']\n",
    "coi = name_to_id['Chingford and Woodford Green']\n",
    "#coi = name_to_id['Bassetlaw']\n",
    "#coi = name_to_id['Bradford West']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_matrix = calc_significance_matrix(demographic_data, \n",
    "                                               scores['uns'], \n",
    "                                               distance_rescale, \n",
    "                                               exponent=10)\n",
    "list_significances(coi, significance_matrix, scores['uns'],30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list_significances(name_to_id['Bradford West'],significance_matrix,scores['uns'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_similar(coi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these onsids to view in the separate notebook: show_constits.ipynb\n",
    "list_similar(coi,30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =np.ndarray.flatten(significance_matrix)\n",
    "b = a[abs(a)>0.2]\n",
    "#sns.distplot(b)\n",
    "#sns.scatterplot(x=a,y=np.ndarray.flatten(10**distance(preprocessing.scale(demographic_data))))#,exponent=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is meant to plot constituencies by demographics, then draw lines between constits that contribute to its result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensetivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_sample_features(features=features,subsample_size=1):\n",
    "    from itertools import combinations\n",
    "    return combinations(features,subsample_size)\n",
    "    #return np.random.choice(features,subsample,replace=False)\n",
    "\n",
    "def noise(array, factor=0.1):\n",
    "    mean = np.mean(array, axis=0)\n",
    "    std = np.std(array, axis=0)\n",
    "    rng = np.random.RandomState()\n",
    "    noise = rng.normal(mean, std * factor, size=array.shape)\n",
    "    return array + noise\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "df = results.copy()\n",
    "print('Drop feature, r2_score')\n",
    "for i,exclude in enumerate(sub_sample_features(subsample_size=1)):\n",
    "    df[i] = calc_campaign_conf(demographic_data.drop(columns=list(exclude)), \n",
    "                               scores['uns'], distance_rescale, exponent=10)\n",
    "    print(exclude,'\\t', r2_score(df['uns_rescale'],df[i]))\n",
    "\n",
    "print('\\n 10% noise to demographics')\n",
    "df = results.copy()\n",
    "for i in range(5):    \n",
    "    df[i] = calc_campaign_conf(noise(demographic_data), scores['uns'], \n",
    "                               distance_rescale, exponent=10)\n",
    "    print(r2_score(df['uns_rescale'],df[i]))\n",
    "    \n",
    "print('\\n 10% noise to score')\n",
    "df = results.copy()\n",
    "for i in range(5):    \n",
    "    df[i] = calc_campaign_conf(demographic_data, noise(scores['uns']), \n",
    "                               distance_rescale, exponent=10)\n",
    "    print(r2_score(df['uns_rescale'],df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#coi = name_to_id['Chingford and Woodford Green']\n",
    "significance_matrix = calc_significance_matrix(demographic_data, scores['uns'])\n",
    "centre_i = id_to_index[coi]\n",
    "contributions = significance_matrix[centre_i]\n",
    "\n",
    "# coi = constits of interest\n",
    "cois = [coi]\n",
    "linexs = []\n",
    "lineys = []\n",
    "values = []\n",
    "\n",
    "N = 10\n",
    "for i in np.flip(np.argsort(np.abs(contributions))[-N:]):\n",
    "    onsid = demographic_data.index[i]\n",
    "    cois += [onsid]\n",
    "    values += [contributions[i]]\n",
    "    #print(contributions[i],id_to_name[onsid,election_results[year]])\n",
    "\n",
    "from sklearn.manifold import Isomap, LocallyLinearEmbedding, SpectralEmbedding, MDS, TSNE\n",
    "embedding = Isomap(n_components=2)\n",
    "from sklearn.decomposition import PCA\n",
    "embedding = PCA(n_components=2)\n",
    "\n",
    "X = demographic_data#[mask]\n",
    "X_transformed = embedding.fit_transform(preprocessing.scale(X))\n",
    "x = pd.Series(X_transformed[:,0])\n",
    "y = pd.Series(X_transformed[:,1])\n",
    "\n",
    "for c in cois:\n",
    "    linexs += [ [x[centre_i],x[id_to_index[c]] ] ]\n",
    "    lineys += [ [y[centre_i],y[id_to_index[c]] ] ]\n",
    "    \n",
    "plt.figure(figsize=(8,8))\n",
    "ax = sns.scatterplot(x=x,y=y)\n",
    "#values = preprocessing.scale(values)\n",
    "for linex,liney,value in zip(linexs,lineys,values):\n",
    "    plt.plot(linex,liney,linewidth=value, color='blue')\n",
    "\n",
    "val = pd.Series([id_to_name[i] for i in X.index])\n",
    "a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "\n",
    "for c in cois:\n",
    "    ax.text(x[id_to_index[c]], y[id_to_index[c]], id_to_name[c])\n",
    "    #ax.text(point['x']+.001, point['y'], str(point['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swing = pd.concat([ scores['uns'],demographic_data],axis=1, verify_integrity=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=swing['uns'],y=swing['c11Unemployed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(scores['uns'].loc[marginals]))\n",
    "sns.distplot(scores['uns'].loc[marginals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=scores['uns'].loc[constits_id],y=census['c11Retired'].loc[constits_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://mycampaignmap.com/graphql/\"\n",
    "params = {\n",
    "    \"query\": \"{\\\n",
    "        constituencies {\\\n",
    "            id\\\n",
    "            name\\\n",
    "            volunteerNeedBand\\\n",
    "            events {\\\n",
    "                properties {\\\n",
    "                    name\\\n",
    "                    startTime\\\n",
    "                }\\\n",
    "            }\\\n",
    "        }\\\n",
    "    }\"\n",
    "}\n",
    "r = requests.get(url, params)\n",
    "data = r.json()[\"data\"]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swing = []\n",
    "n_of_events = []\n",
    "color = []\n",
    "result = []\n",
    "for constit in results.index:\n",
    "    count = 0\n",
    "    for j in data['constituencies']:\n",
    "        if j['id'] == constit:\n",
    "            for event in j['events']:\n",
    "                if any(word in event['properties']['name'].lower() for word in \n",
    "                      ['canvassing','canvasing']):\n",
    "                    if (   ('2019-11' == (event['properties']['startTime'][0:7]))\n",
    "                        or ('2019-12' == (event['properties']['startTime'][0:7]))):\n",
    "                        count += 1\n",
    "                    #print(event)\n",
    "            break\n",
    "    n_of_events += [count]\n",
    "    result += [results.loc[constit, 'uns_rescale_normal']]\n",
    "    swing += [ scores.loc[constit, 'uns']- 0.079 ] \n",
    "    color += [j['volunteerNeedBand']]\n",
    "    #color += [ election_results[year].loc[constit,'winner']]\n",
    "\n",
    "sns.scatterplot(x=result, y=n_of_events, hue=color)\n",
    "            \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "X = np.array(result).reshape(-1,1)\n",
    "y = n_of_events\n",
    "lr.fit(X,y)\n",
    "print(lr.intercept_,lr.coef_,lr.score(X,y))\n",
    "\n",
    "x_fit = np.arange(-2, 2, 0.1)\n",
    "y_fit = lr.intercept_ + x_fit*lr.coef_\n",
    "\n",
    "ax = sns.lineplot(x_fit,y_fit,color='r')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of canvassing events in election period')\n",
    "print(lr.intercept_,float(lr.coef_),lr.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local = pd.read_csv('data/local2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
